{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础MLP网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 2us/step\n",
      "(404, 13)   (404,)\n",
      "(102, 13)   (102,)\n"
     ]
    }
   ],
   "source": [
    "# 导入数据\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.boston_housing.load_data()\n",
    "print(x_train.shape, ' ', y_train.shape)\n",
    "print(x_test.shape, ' ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,593\n",
      "Trainable params: 2,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation='sigmoid', input_shape=(13,)),\n",
    "    layers.Dense(32, activation='sigmoid'),\n",
    "    layers.Dense(32, activation='sigmoid'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(0.1),\n",
    "             loss='mean_squared_error',  # keras.losses.mean_squared_error\n",
    "             metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363 samples, validate on 41 samples\n",
      "Epoch 1/50\n",
      "363/363 [==============================] - 1s 2ms/sample - loss: 429.4809 - mse: 429.4809 - val_loss: 73.2607 - val_mse: 73.2607\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 0s 68us/sample - loss: 90.9447 - mse: 90.9447 - val_loss: 52.4735 - val_mse: 52.4735\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 0s 81us/sample - loss: 91.0002 - mse: 91.0002 - val_loss: 54.8558 - val_mse: 54.8558\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 0s 67us/sample - loss: 90.8310 - mse: 90.8310 - val_loss: 48.7508 - val_mse: 48.7508\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 0s 80us/sample - loss: 91.8133 - mse: 91.8133 - val_loss: 80.9737 - val_mse: 80.9737\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 0s 63us/sample - loss: 93.6262 - mse: 93.6262 - val_loss: 44.3465 - val_mse: 44.3465\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 0s 85us/sample - loss: 90.6451 - mse: 90.6451 - val_loss: 55.8164 - val_mse: 55.8164\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 0s 90us/sample - loss: 92.8948 - mse: 92.8948 - val_loss: 45.0471 - val_mse: 45.0471\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 0s 74us/sample - loss: 89.5199 - mse: 89.5199 - val_loss: 46.5527 - val_mse: 46.5527\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 0s 67us/sample - loss: 91.0244 - mse: 91.0245 - val_loss: 47.2286 - val_mse: 47.2286\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 0s 78us/sample - loss: 89.4144 - mse: 89.4144 - val_loss: 72.9836 - val_mse: 72.9836\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 0s 71us/sample - loss: 91.1479 - mse: 91.1479 - val_loss: 46.6357 - val_mse: 46.6357\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 0s 80us/sample - loss: 91.1048 - mse: 91.1048 - val_loss: 42.5324 - val_mse: 42.5324\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 0s 91us/sample - loss: 90.1537 - mse: 90.1537 - val_loss: 56.2592 - val_mse: 56.2592\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 0s 65us/sample - loss: 92.0609 - mse: 92.0609 - val_loss: 42.4458 - val_mse: 42.4458\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 0s 79us/sample - loss: 89.7073 - mse: 89.7073 - val_loss: 42.3606 - val_mse: 42.3606\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 0s 74us/sample - loss: 90.1723 - mse: 90.1723 - val_loss: 59.9798 - val_mse: 59.9798\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 0s 61us/sample - loss: 91.4395 - mse: 91.4395 - val_loss: 49.3275 - val_mse: 49.3275\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 0s 77us/sample - loss: 91.7221 - mse: 91.7221 - val_loss: 56.2412 - val_mse: 56.2412\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 0s 73us/sample - loss: 93.5402 - mse: 93.5402 - val_loss: 42.6919 - val_mse: 42.6919\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 0s 64us/sample - loss: 88.9785 - mse: 88.9786 - val_loss: 43.6453 - val_mse: 43.6453\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 0s 79us/sample - loss: 92.8700 - mse: 92.8700 - val_loss: 41.9222 - val_mse: 41.9222\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 0s 94us/sample - loss: 90.2691 - mse: 90.2691 - val_loss: 42.4522 - val_mse: 42.4522\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 0s 67us/sample - loss: 89.4269 - mse: 89.4269 - val_loss: 43.1772 - val_mse: 43.1772\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 0s 72us/sample - loss: 86.7177 - mse: 86.7177 - val_loss: 57.4204 - val_mse: 57.4204\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 0s 87us/sample - loss: 92.8946 - mse: 92.8946 - val_loss: 41.2289 - val_mse: 41.2289\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 0s 59us/sample - loss: 90.0863 - mse: 90.0863 - val_loss: 41.9422 - val_mse: 41.9422\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 0s 78us/sample - loss: 86.5305 - mse: 86.5305 - val_loss: 39.3888 - val_mse: 39.3888\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 0s 69us/sample - loss: 85.5233 - mse: 85.5233 - val_loss: 38.7569 - val_mse: 38.7569\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 0s 78us/sample - loss: 85.1915 - mse: 85.1915 - val_loss: 42.9035 - val_mse: 42.9035\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 0s 90us/sample - loss: 91.1276 - mse: 91.1276 - val_loss: 37.1215 - val_mse: 37.1215\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 0s 67us/sample - loss: 84.8535 - mse: 84.8535 - val_loss: 63.6413 - val_mse: 63.6413\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 0s 63us/sample - loss: 86.2846 - mse: 86.2846 - val_loss: 37.6689 - val_mse: 37.6689\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 0s 78us/sample - loss: 83.7213 - mse: 83.7213 - val_loss: 54.6897 - val_mse: 54.6897\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 0s 66us/sample - loss: 94.0416 - mse: 94.0416 - val_loss: 54.2293 - val_mse: 54.2293\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 0s 63us/sample - loss: 90.2597 - mse: 90.2597 - val_loss: 50.4561 - val_mse: 50.4561\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 0s 67us/sample - loss: 90.9261 - mse: 90.9261 - val_loss: 63.3088 - val_mse: 63.3088\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 0s 74us/sample - loss: 94.0995 - mse: 94.0995 - val_loss: 58.0208 - val_mse: 58.0208\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 0s 81us/sample - loss: 92.4609 - mse: 92.4609 - val_loss: 42.6672 - val_mse: 42.6672\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 0s 67us/sample - loss: 89.3565 - mse: 89.3565 - val_loss: 43.1417 - val_mse: 43.1417\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 0s 65us/sample - loss: 90.0818 - mse: 90.0818 - val_loss: 48.8173 - val_mse: 48.8173\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 0s 59us/sample - loss: 90.5606 - mse: 90.5606 - val_loss: 44.7716 - val_mse: 44.7716\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 0s 62us/sample - loss: 90.8423 - mse: 90.8423 - val_loss: 49.2521 - val_mse: 49.2521\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 0s 66us/sample - loss: 93.0605 - mse: 93.0605 - val_loss: 42.8474 - val_mse: 42.8474\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 0s 56us/sample - loss: 90.2966 - mse: 90.2966 - val_loss: 46.3300 - val_mse: 46.3300\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 0s 70us/sample - loss: 89.7445 - mse: 89.7445 - val_loss: 43.6920 - val_mse: 43.6920\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 0s 60us/sample - loss: 91.0473 - mse: 91.0473 - val_loss: 61.8990 - val_mse: 61.8990\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 0s 63us/sample - loss: 93.5327 - mse: 93.5327 - val_loss: 46.4528 - val_mse: 46.4528\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 0s 74us/sample - loss: 91.9477 - mse: 91.9477 - val_loss: 46.1696 - val_mse: 46.1696\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 0s 70us/sample - loss: 92.3818 - mse: 92.3818 - val_loss: 52.9188 - val_mse: 52.9188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ac95208>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "model.fit(x_train, y_train, batch_size=50, epochs=50, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "102/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 55us/sample - loss: 176.2013 - mse: 105.9553\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mse']\n",
      "[105.95535368077896, 105.955345]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)   (398,)\n",
      "(171, 30)   (171,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 导入数据\n",
    "whole_data = load_breast_cancer()\n",
    "x_data = whole_data.data\n",
    "y_data = whole_data.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=7)\n",
    "\n",
    "print(x_train.shape, ' ', y_train.shape)\n",
    "print(x_test.shape, ' ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                992       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(30,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=keras.losses.binary_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0906 10:49:43.853066 140735620006784 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples\n",
      "Epoch 1/10\n",
      "398/398 [==============================] - 0s 961us/sample - loss: 51.1729 - accuracy: 0.3945\n",
      "Epoch 2/10\n",
      "398/398 [==============================] - 0s 43us/sample - loss: 28.5194 - accuracy: 0.3945\n",
      "Epoch 3/10\n",
      "398/398 [==============================] - 0s 44us/sample - loss: 7.9520 - accuracy: 0.3995\n",
      "Epoch 4/10\n",
      "398/398 [==============================] - 0s 51us/sample - loss: 10.3602 - accuracy: 0.6055\n",
      "Epoch 5/10\n",
      "398/398 [==============================] - 0s 46us/sample - loss: 2.4345 - accuracy: 0.5854\n",
      "Epoch 6/10\n",
      "398/398 [==============================] - 0s 51us/sample - loss: 1.8210 - accuracy: 0.6784\n",
      "Epoch 7/10\n",
      "398/398 [==============================] - 0s 43us/sample - loss: 1.2080 - accuracy: 0.8769\n",
      "Epoch 8/10\n",
      "398/398 [==============================] - 0s 47us/sample - loss: 0.9876 - accuracy: 0.8945\n",
      "Epoch 9/10\n",
      "398/398 [==============================] - 0s 52us/sample - loss: 0.7782 - accuracy: 0.8618\n",
      "Epoch 10/10\n",
      "398/398 [==============================] - 0s 50us/sample - loss: 0.7316 - accuracy: 0.8744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13b242630>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 485us/sample - loss: 0.3042 - accuracy: 0.9123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5662652929231786, 0.9122807]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
