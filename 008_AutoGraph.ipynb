{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.function 的一个很酷的新功能是 AutoGraph，它允许使用自然的 Python 语法编写图形代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_util\n",
    "control_flow_util.ENABLE_CONTROL_FLOW_V2 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.function 装饰器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当使用 tf.function 注释函数时，可以像调用任何其他函数一样调用它。 它将被编译成图，这意味着可以获得更快执行，更好地在 GPU 或 TPU 上运行或导出到 SavedModel。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.79224634, 1.2441946 , 1.4953172 ],\n",
       "       [0.56591576, 0.97079694, 1.1965573 ],\n",
       "       [0.68131983, 1.2662568 , 1.540731  ]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def simple_nn_layer(x, y):\n",
    "    return tf.nn.relu(tf.matmul(x, y))\n",
    "\n",
    "\n",
    "x = tf.random.uniform((3, 3))\n",
    "y = tf.random.uniform((3, 3))\n",
    "\n",
    "simple_nn_layer(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们检查注释的结果，我们可以看到它是一个特殊的可调用函数，它处理与TensorFlow运行时的所有交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x130e3dac8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_nn_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果代码使用多个函数，则无需对它们进行全部注释,\n",
    "**从带注释函数调用的任何函数也将以图形模式运行**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=35, shape=(3,), dtype=int32, numpy=array([3, 5, 7], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_layer(x):\n",
    "    return 2 * x + 1\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def deep_net(x):\n",
    "    return tf.nn.relu(linear_layer(x))\n",
    "\n",
    "\n",
    "deep_net(tf.constant((1, 2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Python 控制流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 tf.function 中使用依赖于数据的控制流时，可以使用 Python 控制流语句，AutoGraph 会将它们转换为适当的 TensorFlow 操作。 例如，如果语句依赖于 Tensor，则语句将转换为 tf.cond()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square_if_positive(2) = 4\n",
      "square_if_positive(-2) = 0\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def square_if_positive(x):\n",
    "    if x > 0:\n",
    "        x = x * x\n",
    "    else:\n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))\n",
    "print('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGraph 支持常见的 Python 语句，例如 while，if，break，continue 和 return，支持嵌套。 这意味着可以在 while 和 if 语句的条件下使用 Tensor 表达式，或者在 for 循环中迭代 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=142, shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def sum_even(items):\n",
    "    s = 0\n",
    "    for c in items:\n",
    "        if c % 2 > 0:\n",
    "            continue\n",
    "        s += c\n",
    "    return s\n",
    "\n",
    "sum_even(tf.constant([10, 12, 15, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGraph 还为高级用户提供了低级 API。 例如，我们可以使用它来查看生成的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__sum_even(items):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('sum_even', 'sum_even_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as sum_even_scope:\n",
      "    s = 0\n",
      "\n",
      "    def get_state_2():\n",
      "      return ()\n",
      "\n",
      "    def set_state_2(_):\n",
      "      pass\n",
      "\n",
      "    def loop_body(iterates, s):\n",
      "      c = iterates\n",
      "      continue_ = False\n",
      "\n",
      "      def get_state():\n",
      "        return ()\n",
      "\n",
      "      def set_state(_):\n",
      "        pass\n",
      "\n",
      "      def if_true():\n",
      "        continue_ = True\n",
      "        return continue_\n",
      "\n",
      "      def if_false():\n",
      "        return continue_\n",
      "      cond = c % 2 > 0\n",
      "      continue_ = ag__.if_stmt(cond, if_true, if_false, get_state, set_state, ('continue_',), ())\n",
      "\n",
      "      def get_state_1():\n",
      "        return ()\n",
      "\n",
      "      def set_state_1(_):\n",
      "        pass\n",
      "\n",
      "      def if_true_1():\n",
      "        s_1, = s,\n",
      "        s_1 += c\n",
      "        return s_1\n",
      "\n",
      "      def if_false_1():\n",
      "        return s\n",
      "      cond_1 = ag__.not_(continue_)\n",
      "      s = ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_1, set_state_1, ('s',), ())\n",
      "      return s,\n",
      "    s, = ag__.for_stmt(items, None, loop_body, get_state_2, set_state_2, (s,), ('s',), ())\n",
      "    do_return = True\n",
      "    retval_ = sum_even_scope.mark_return_value(s)\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.autograph.to_code(sum_even.python_function, experimental_optional_features=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个更复杂的控制流程的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fizz\n",
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def fizzbuzz(n):\n",
    "    msg = tf.constant('')\n",
    "    for i in tf.range(n):\n",
    "        if tf.equal(i % 3, 0):\n",
    "            msg += 'Fizz'\n",
    "        elif tf.equal(i % 5, 0):\n",
    "            msg += 'Buzz'\n",
    "        else:\n",
    "            msg += tf.as_string(i)\n",
    "        msg += '\\n'\n",
    "    return msg\n",
    "\n",
    "print(fizzbuzz(tf.constant(15)).numpy().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras 和 AutoGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以将 tf.function 与对象方法一起使用。 例如，可以通过注释模型的调用函数来装饰自定义 Keras 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=263, shape=(2,), dtype=int32, numpy=array([-1, -2], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(tf.keras.models.Model):\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_data):\n",
    "        if tf.reduce_mean(input_data) > 0:\n",
    "            return input_data\n",
    "        else:\n",
    "            return input_data // 2\n",
    "\n",
    "model = CustomModel()\n",
    "model(tf.constant([-2, -4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**副作用**：就像在 eager 模式下一样，你可以使用带有副作用的操作，比如通常在 tf.function 中的 tf.assign 或 tf.print，它会插入必要的控件依赖项以确保它们按顺序执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(5)\n",
    "\n",
    "@tf.function\n",
    "def find_next_odd():\n",
    "    v.assign(v + 1)\n",
    "    if tf.equal(v % 2, 0):\n",
    "        v.assign(v + 1)\n",
    "\n",
    "\n",
    "find_next_odd()\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用 AutoGraph 训练一个简单模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10 : loss 1.7814002 ; accuracy 0.304\n",
      "Step 20 : loss 1.22172511 ; accuracy 0.4895\n",
      "Step 30 : loss 0.801277697 ; accuracy 0.59\n",
      "Step 40 : loss 0.777820647 ; accuracy 0.64575\n",
      "Step 50 : loss 0.537724 ; accuracy 0.6908\n",
      "Step 60 : loss 0.563764334 ; accuracy 0.722166657\n",
      "Step 70 : loss 0.382106632 ; accuracy 0.746714294\n",
      "Step 80 : loss 0.502317071 ; accuracy 0.7625\n",
      "Step 90 : loss 0.476850361 ; accuracy 0.776111126\n",
      "Step 100 : loss 0.318636358 ; accuracy 0.7881\n",
      "Step 110 : loss 0.261523962 ; accuracy 0.799363613\n",
      "Step 120 : loss 0.394204259 ; accuracy 0.807916641\n",
      "Step 130 : loss 0.286721498 ; accuracy 0.815846145\n",
      "Step 140 : loss 0.386131197 ; accuracy 0.822\n",
      "Step 150 : loss 0.307116717 ; accuracy 0.8274\n",
      "Step 160 : loss 0.317753911 ; accuracy 0.833437502\n",
      "Step 170 : loss 0.289032489 ; accuracy 0.838470578\n",
      "Step 180 : loss 0.435914338 ; accuracy 0.8435\n",
      "Step 190 : loss 0.199862346 ; accuracy 0.848105252\n",
      "Step 200 : loss 0.309946358 ; accuracy 0.85165\n",
      "Final step tf.Tensor(200, shape=(), dtype=int32) : loss tf.Tensor(0.30994636, shape=(), dtype=float32) ; accuracy tf.Tensor(0.85165, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def prepare_mnist_features_and_labels(x, y):\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    return x, y\n",
    "\n",
    "def mnist_dataset():\n",
    "    (x, y), _ = tf.keras.datasets.mnist.load_data()\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    ds = ds.map(prepare_mnist_features_and_labels)\n",
    "    ds = ds.take(20000).shuffle(20000).batch(100)\n",
    "    return ds\n",
    "\n",
    "# train_dataset = mnist_dataset()\n",
    "\n",
    "model = tf.keras.Sequential((\n",
    "    tf.keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)))\n",
    "model.build()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "def train_one_step(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss = compute_loss(y, logits)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    compute_accuracy(y, logits)\n",
    "    return loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train(model, optimizer):\n",
    "    train_ds = mnist_dataset()\n",
    "    step = 0\n",
    "    loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for x, y in train_ds:\n",
    "        step += 1\n",
    "        loss = train_one_step(model, optimizer, x, y)\n",
    "        if tf.equal(step % 10, 0):\n",
    "            tf.print('Step', step, ': loss', loss, '; accuracy', compute_accuracy.result())\n",
    "    return step, loss, accuracy\n",
    "\n",
    "step, loss, accuracy = train(model, optimizer)\n",
    "print('Final step', step, ': loss', loss, '; accuracy', compute_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关于批处理的说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实际应用中，批处理对性能至关重要。 转换为 AutoGraph 的最佳代码是在批处理级别决定控制流的代码。 如果在单个示例级别做出决策，请尝试使用批处理 API 来维护性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, -4, -3, -2, -1, 0, 1, 4, 9, 16]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_if_positive(x):\n",
    "    return [i ** 2 if i > 0 else i for i in x]\n",
    "\n",
    "square_if_positive(range(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1186, shape=(10,), dtype=int32, numpy=array([-5, -4, -3, -2, -1,  0,  1,  4,  9, 16], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在tensorflow中上面的代码应该改成下面所示\n",
    "@tf.function\n",
    "def square_if_positive_naive(x):\n",
    "    result = tf.TensorArray(tf.int32, size=x.shape[0])\n",
    "    for i in tf.range(x.shape[0]):\n",
    "        if x[i] > 0:\n",
    "            result = result.write(i, x[i] ** 2)\n",
    "        else:\n",
    "            result = result.write(i, x[i])\n",
    "    return result.stack()\n",
    "\n",
    "square_if_positive_naive(tf.range(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1195, shape=(10,), dtype=int32, numpy=array([-5, -4, -3, -2, -1,  0,  1,  4,  9, 16], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推荐这么写 tf.where\n",
    "def square_if_positive_vectorized(x):\n",
    "    return tf.where(x > 0, x ** 2, x)\n",
    "\n",
    "square_if_positive_vectorized(tf.range(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
