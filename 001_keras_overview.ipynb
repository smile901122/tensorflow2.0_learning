{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 快速入门"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras 是一个用于构建和训练深度学习模型的高阶 API。它可用于快速设计原型、高级研究和生产。\n",
    "\n",
    "keras的3个优点： 方便用户使用、模块化和可组合、易于扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow2推荐使用keras构建网络，常见的神经网络都包含在keras.layer中(最新的tf.keras的版本可能和keras不同)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建简单模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型堆叠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最常见的模型类型是层的堆叠：tf.keras.Sequential 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.layers中网络配置：\n",
    "\n",
    "activation：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。\n",
    "\n",
    "kernel_initializer 和 bias_initializer：创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 \"Glorot uniform\" 初始化器。\n",
    "\n",
    "kernel_regularizer 和 bias_regularizer：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x112233e10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Dense(32, activation='sigmoid')\n",
    "layers.Dense(32, activation=tf.sigmoid)\n",
    "layers.Dense(32, kernel_initializer='orthogonal')\n",
    "layers.Dense(32, kernel_initializer=tf.keras.initializers.glorot_normal)\n",
    "layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l1(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置训练流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建好模型后，通过调用 compile 方法配置该模型的学习流程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入 numpy 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 243us/sample - loss: 11.8337 - categorical_accuracy: 0.1060 - val_loss: 11.7481 - val_categorical_accuracy: 0.0750\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 16us/sample - loss: 12.2477 - categorical_accuracy: 0.1100 - val_loss: 12.4739 - val_categorical_accuracy: 0.0900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 23us/sample - loss: 13.4240 - categorical_accuracy: 0.1100 - val_loss: 14.1404 - val_categorical_accuracy: 0.0850\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 21us/sample - loss: 15.5383 - categorical_accuracy: 0.1090 - val_loss: 16.4838 - val_categorical_accuracy: 0.0850\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 26us/sample - loss: 17.9796 - categorical_accuracy: 0.1090 - val_loss: 18.8139 - val_categorical_accuracy: 0.0800\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 27us/sample - loss: 20.4782 - categorical_accuracy: 0.1060 - val_loss: 21.6518 - val_categorical_accuracy: 0.0750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 23.8816 - categorical_accuracy: 0.0970 - val_loss: 25.4550 - val_categorical_accuracy: 0.0900\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 28.0307 - categorical_accuracy: 0.0990 - val_loss: 29.7816 - val_categorical_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 25us/sample - loss: 32.7652 - categorical_accuracy: 0.1010 - val_loss: 35.0340 - val_categorical_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 23us/sample - loss: 38.7594 - categorical_accuracy: 0.0990 - val_loss: 41.7763 - val_categorical_accuracy: 0.0950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1344ddef0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_x = np.random.random((1000, 72))\n",
    "train_y = np.random.random((1000, 10))\n",
    "\n",
    "val_x = np.random.random((200, 72))\n",
    "val_y = np.random.random((200, 10))\n",
    "\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=100,\n",
    "          validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data 输入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 13:55:26.233390 140735620006784 training_utils.py:1353] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 55.8843 - categorical_accuracy: 0.0938 - val_loss: 71.5970 - val_categorical_accuracy: 0.0938\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 92.3780 - categorical_accuracy: 0.0887 - val_loss: 115.0767 - val_categorical_accuracy: 0.1042\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 144.1701 - categorical_accuracy: 0.0919 - val_loss: 172.9283 - val_categorical_accuracy: 0.1146\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 209.7446 - categorical_accuracy: 0.0972 - val_loss: 243.3316 - val_categorical_accuracy: 0.1146\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 287.5578 - categorical_accuracy: 0.0940 - val_loss: 326.3305 - val_categorical_accuracy: 0.1146\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 377.6972 - categorical_accuracy: 0.0962 - val_loss: 419.9674 - val_categorical_accuracy: 0.1667\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 476.5737 - categorical_accuracy: 0.0951 - val_loss: 518.9161 - val_categorical_accuracy: 0.1250\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 581.6093 - categorical_accuracy: 0.1047 - val_loss: 618.7995 - val_categorical_accuracy: 0.1354\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 685.1299 - categorical_accuracy: 0.1058 - val_loss: 720.2223 - val_categorical_accuracy: 0.1667\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 787.9588 - categorical_accuracy: 0.0962 - val_loss: 817.7669 - val_categorical_accuracy: 0.1146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x135557b00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "val_dataset = val_dataset.repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset, validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 20us/sample - loss: 840.3754 - categorical_accuracy: 0.1010\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 841.3636 - categorical_accuracy: 0.1010\n",
      "[[0.18235317 0.         0.30762902 ... 0.12508483 0.         0.        ]\n",
      " [0.17952919 0.         0.36265895 ... 0.09341178 0.         0.        ]\n",
      " [0.14166033 0.         0.27668113 ... 0.1187089  0.         0.        ]\n",
      " ...\n",
      " [0.17406106 0.         0.3531616  ... 0.089119   0.         0.        ]\n",
      " [0.1232493  0.         0.24921368 ... 0.12033546 0.         0.        ]\n",
      " [0.16565922 0.         0.28805614 ... 0.09891963 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "test_x = np.random.random((1000, 72))\n",
    "test_y = np.random.random((1000, 10))\n",
    "model.evaluate(test_x, test_y, batch_size=32)\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "test_data = test_data.batch(32).repeat()\n",
    "model.evaluate(test_data, steps=30)\n",
    "# predict\n",
    "result = model.predict(test_x, batch_size=32)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建高级模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数式 api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.Sequential 模型是层的简单堆叠，无法表示任意模型。使用 Keras 函数式 API 可以构建复杂的模型拓扑，例如：\n",
    "\n",
    "多输入模型，\n",
    "\n",
    "多输出模型，\n",
    "\n",
    "具有共享层的模型（同一层被调用多次），\n",
    "\n",
    "具有非序列数据流的模型（例如，残差连接）。\n",
    "\n",
    "**使用函数式 API 构建的模型具有以下特征：**\n",
    "\n",
    "层实例可调用并返回张量。 输入张量和输出张量用于定义 tf.keras.Model 实例。 此模型的训练方式和 Sequential 模型一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 12.0184 - accuracy: 0.0960\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 16.1963 - accuracy: 0.1020\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 31.9784 - accuracy: 0.0970\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 61.0569 - accuracy: 0.0970\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 108.6143 - accuracy: 0.0920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13570c9b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_x = tf.keras.Input(shape=(72,))\n",
    "hidden1 = layers.Dense(32, activation='relu')(input_x)\n",
    "hidden2 = layers.Dense(16, activation='relu')(hidden1)\n",
    "pred = layers.Dense(10, activation='softmax')(hidden2)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_x, outputs=pred)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型子类化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对 tf.keras.Model 进行子类化并定义您自己的前向传播来构建完全可自定义的模型。在 init 方法中创建层并将它们设置为类实例的属性。在 call 方法中定义前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 153us/sample - loss: 13.2253 - accuracy: 0.1070\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 18.6069 - accuracy: 0.1130\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 24.9853 - accuracy: 0.1090\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 32.2452 - accuracy: 0.1090\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 39.1751 - accuracy: 0.1170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x135c6b4e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        self.layer1 = layers.Dense(32, activation='relu')\n",
    "        self.layer2 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        h1 = self.layer1(inputs)\n",
    "        out = self.layer2(h1)\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.num_classes\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "model = MyModel(num_classes=10)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对 tf.keras.layers.Layer 进行子类化并实现以下方法来创建自定义层：\n",
    "\n",
    "build：创建层的权重。使用 add_weight 方法添加权重。\n",
    "\n",
    "call：定义前向传播。\n",
    "\n",
    "compute_output_shape：指定在给定输入形状的情况下如何计算层的输出形状。 或者，可以通过实现 get_config 方法和 from_config 类方法序列化层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 11.6052 - accuracy: 0.1030\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 11.6030 - accuracy: 0.1060\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 11.5998 - accuracy: 0.1050\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 11.5992 - accuracy: 0.1010\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 11.5971 - accuracy: 0.1120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1361a7588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "        self.kernel = self.add_weight(name='kernel1', shape=shape,\n",
    "                                   initializer='uniform', trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "model = tf.keras.Sequential([MyLayer(10), layers.Activation('softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 194us/sample - loss: 11.5956 - accuracy: 0.1020 - val_loss: 11.4014 - val_accuracy: 0.1100\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 11.5940 - accuracy: 0.1080 - val_loss: 11.4016 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 11.5926 - accuracy: 0.1050 - val_loss: 11.3950 - val_accuracy: 0.1100\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 11.5896 - accuracy: 0.1050 - val_loss: 11.3969 - val_accuracy: 0.1050\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 11.5892 - accuracy: 0.1030 - val_loss: 11.3909 - val_accuracy: 0.0950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x135c647f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "#     tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "    ]\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5,\n",
    "         callbacks=callbacks, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和恢复"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 权重保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 146us/sample - loss: 14.9703 - accuracy: 0.0980\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 22.5261 - accuracy: 0.0960\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 27.5786 - accuracy: 0.1020\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 33.1081 - accuracy: 0.0910\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 34.1960 - accuracy: 0.0910\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5)\n",
    "\n",
    "model.save_weights('./ch1/weights/model')\n",
    "model.load_weights('./ch1/weights/model')\n",
    "model.save_weights('./ch1/model.h5')\n",
    "model.load_weights('./ch1/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "序列化为 json:\n",
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': {'build_input_shape': [None, 72],\n",
      "            'layers': [{'class_name': 'Dense',\n",
      "                        'config': {'activation': 'relu',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_17',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 64,\n",
      "                                   'use_bias': True}},\n",
      "                       {'class_name': 'Dense',\n",
      "                        'config': {'activation': 'softmax',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_18',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 10,\n",
      "                                   'use_bias': True}}],\n",
      "            'name': 'sequential_3'},\n",
      " 'keras_version': '2.2.4-tf'}\n",
      "----------------------------------------------\n",
      "序列化为 yaml:\n",
      "backend: tensorflow\n",
      "class_name: Sequential\n",
      "config:\n",
      "  build_input_shape: !!python/tuple\n",
      "  - null\n",
      "  - 72\n",
      "  layers:\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: relu\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config:\n",
      "          seed: null\n",
      "      kernel_regularizer: null\n",
      "      name: dense_17\n",
      "      trainable: true\n",
      "      units: 64\n",
      "      use_bias: true\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: softmax\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config:\n",
      "          seed: null\n",
      "      kernel_regularizer: null\n",
      "      name: dense_18\n",
      "      trainable: true\n",
      "      units: 10\n",
      "      use_bias: true\n",
      "  name: sequential_3\n",
      "keras_version: 2.2.4-tf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/saving/model_config.py:76: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    }
   ],
   "source": [
    "# 序列化成json\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "json_str = model.to_json()\n",
    "# 使用 pprint 美观打印\n",
    "print('序列化为 json:')\n",
    "pprint.pprint(json.loads(json_str))\n",
    "fresh_model = tf.keras.models.model_from_json(json_str)\n",
    "\n",
    "print('----------------------------------------------')\n",
    "\n",
    "# 保持为yaml格式  \n",
    "# 需要提前安装pyyaml\n",
    "yaml_str = model.to_yaml()\n",
    "print('序列化为 yaml:')\n",
    "print(yaml_str)\n",
    "fresh_model = tf.keras.models.model_from_yaml(yaml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存整个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 11.5664 - accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 11.5952 - accuracy: 0.0930\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 11.6507 - accuracy: 0.0930\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 11.6703 - accuracy: 0.0930\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 11.6757 - accuracy: 0.0930\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(10, activation='softmax', input_shape=(72,)),\n",
    "  layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=5)\n",
    "\n",
    "model.save('./ch1/all_model.h5')\n",
    "model = tf.keras.models.load_model('./ch1/all_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将 Keras 用于 Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator API 用于针对分布式环境训练模型。它适用于一些行业使用场景，例如用大型数据集进行分布式训练并导出模型以用于生产"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 13:56:23.571402 140735620006784 estimator.py:1799] Using temporary folder as model directory: /var/folders/gt/gzycyzkn1tbg30xkr04j1g900000gn/T/tmp0ejjn32i\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([layers.Dense(10,activation='softmax'),\n",
    "                          layers.Dense(10,activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "estimator = tf.keras.estimator.model_to_estimator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只要用 tf.keras.estimator.model_to_estimator 方法将 tf.keras.Model 转换为 tf.estimator.Estimator 对象, tf.keras.Model 就可以使用 tf.estimator API 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
