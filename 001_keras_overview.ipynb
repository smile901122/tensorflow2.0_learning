{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 快速入门"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras 是一个用于构建和训练深度学习模型的高阶 API。它可用于快速设计原型、高级研究和生产。\n",
    "\n",
    "keras的3个优点： 方便用户使用、模块化和可组合、易于扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow2推荐使用keras构建网络，常见的神经网络都包含在keras.layer中(最新的tf.keras的版本可能和keras不同)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建简单模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型堆叠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最常见的模型类型是层的堆叠：tf.keras.Sequential 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0810 20:41:26.426313  6468 deprecation.py:506] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.layers中网络配置：\n",
    "\n",
    "activation：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。\n",
    "\n",
    "kernel_initializer 和 bias_initializer：创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 \"Glorot uniform\" 初始化器。\n",
    "\n",
    "kernel_regularizer 和 bias_regularizer：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1bd1e4507f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Dense(32, activation='sigmoid')\n",
    "layers.Dense(32, activation=tf.sigmoid)\n",
    "layers.Dense(32, kernel_initializer='orthogonal')\n",
    "layers.Dense(32, kernel_initializer=tf.keras.initializers.glorot_normal)\n",
    "layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l1(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置训练流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建好模型后，通过调用 compile 方法配置该模型的学习流程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入 numpy 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 626us/sample - loss: 12.5915 - categorical_accuracy: 0.1080 - val_loss: 12.9621 - val_categorical_accuracy: 0.1300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 21us/sample - loss: 13.0380 - categorical_accuracy: 0.1230 - val_loss: 13.8799 - val_categorical_accuracy: 0.1200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 21us/sample - loss: 14.3821 - categorical_accuracy: 0.0850 - val_loss: 16.1149 - val_categorical_accuracy: 0.1050\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 21us/sample - loss: 17.4926 - categorical_accuracy: 0.0890 - val_loss: 20.7250 - val_categorical_accuracy: 0.1150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 20us/sample - loss: 22.8636 - categorical_accuracy: 0.0870 - val_loss: 27.0735 - val_categorical_accuracy: 0.1150\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 20us/sample - loss: 28.7496 - categorical_accuracy: 0.0890 - val_loss: 33.2714 - val_categorical_accuracy: 0.0950\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 21us/sample - loss: 35.8230 - categorical_accuracy: 0.0930 - val_loss: 42.5615 - val_categorical_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 20us/sample - loss: 46.1008 - categorical_accuracy: 0.0950 - val_loss: 54.8224 - val_categorical_accuracy: 0.0900\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 18us/sample - loss: 58.7988 - categorical_accuracy: 0.1010 - val_loss: 69.2874 - val_categorical_accuracy: 0.0800\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 21us/sample - loss: 73.3665 - categorical_accuracy: 0.1000 - val_loss: 85.7787 - val_categorical_accuracy: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bd19c76cf8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_x = np.random.random((1000, 72))\n",
    "train_y = np.random.random((1000, 10))\n",
    "\n",
    "val_x = np.random.random((200, 72))\n",
    "val_y = np.random.random((200, 10))\n",
    "\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=100,\n",
    "          validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data 输入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0810 20:55:31.986442  6468 training_utils.py:1300] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 109.7410 - categorical_accuracy: 0.0938 - val_loss: 155.0785 - val_categorical_accuracy: 0.0625\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 184.7956 - categorical_accuracy: 0.0940 - val_loss: 250.6502 - val_categorical_accuracy: 0.0938\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 290.1126 - categorical_accuracy: 0.0919 - val_loss: 376.1395 - val_categorical_accuracy: 0.1146\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 410.4020 - categorical_accuracy: 0.0951 - val_loss: 517.3589 - val_categorical_accuracy: 0.1250\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 552.3217 - categorical_accuracy: 0.0908 - val_loss: 675.9874 - val_categorical_accuracy: 0.1250\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 704.1227 - categorical_accuracy: 0.0833 - val_loss: 848.0327 - val_categorical_accuracy: 0.0938\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 865.4562 - categorical_accuracy: 0.0823 - val_loss: 1027.3758 - val_categorical_accuracy: 0.1250\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1032.8609 - categorical_accuracy: 0.0940 - val_loss: 1199.7705 - val_categorical_accuracy: 0.1354\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1184.8398 - categorical_accuracy: 0.0865 - val_loss: 1350.2677 - val_categorical_accuracy: 0.0729\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1302.6001 - categorical_accuracy: 0.0887 - val_loss: 1479.6855 - val_categorical_accuracy: 0.0417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bed8c6d390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "val_dataset = val_dataset.repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset, validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 58us/sample - loss: 1374.7034 - categorical_accuracy: 0.0940\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1370.2131 - categorical_accuracy: 0.0938\n",
      "[[0.         0.         0.00567246 ... 0.28867733 0.21939978 0.        ]\n",
      " [0.         0.         0.00341834 ... 0.2752905  0.25163588 0.        ]\n",
      " [0.         0.         0.00230477 ... 0.20787466 0.35291672 0.        ]\n",
      " ...\n",
      " [0.         0.         0.00470895 ... 0.22889282 0.20759678 0.        ]\n",
      " [0.         0.         0.00225743 ... 0.18556562 0.37121    0.        ]\n",
      " [0.         0.         0.00754409 ... 0.28670672 0.31396455 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "test_x = np.random.random((1000, 72))\n",
    "test_y = np.random.random((1000, 10))\n",
    "model.evaluate(test_x, test_y, batch_size=32)\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "test_data = test_data.batch(32).repeat()\n",
    "model.evaluate(test_data, steps=30)\n",
    "# predict\n",
    "result = model.predict(test_x, batch_size=32)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建高级模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数式 api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.Sequential 模型是层的简单堆叠，无法表示任意模型。使用 Keras 函数式 API 可以构建复杂的模型拓扑，例如：\n",
    "\n",
    "多输入模型，\n",
    "\n",
    "多输出模型，\n",
    "\n",
    "具有共享层的模型（同一层被调用多次），\n",
    "\n",
    "具有非序列数据流的模型（例如，残差连接）。\n",
    "\n",
    "**使用函数式 API 构建的模型具有以下特征：**\n",
    "\n",
    "层实例可调用并返回张量。 输入张量和输出张量用于定义 tf.keras.Model 实例。 此模型的训练方式和 Sequential 模型一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 12.6879 - acc: 0.0940\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 18.5924 - acc: 0.1070\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 33.6198 - acc: 0.1060\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 62.7332 - acc: 0.1050\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 107.9833 - acc: 0.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bed8d31ac8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_x = tf.keras.Input(shape=(72,))\n",
    "hidden1 = layers.Dense(32, activation='relu')(input_x)\n",
    "hidden2 = layers.Dense(16, activation='relu')(hidden1)\n",
    "pred = layers.Dense(10, activation='softmax')(hidden2)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_x, outputs=pred)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型子类化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对 tf.keras.Model 进行子类化并定义您自己的前向传播来构建完全可自定义的模型。在 init 方法中创建层并将它们设置为类实例的属性。在 call 方法中定义前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 140us/sample - loss: 14.1145 - acc: 0.0940\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 17.8594 - acc: 0.1130\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 20.7122 - acc: 0.1120\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 22.3641 - acc: 0.1010\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 22.7968 - acc: 0.1030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bee4ecefd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        self.layer1 = layers.Dense(32, activation='relu')\n",
    "        self.layer2 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        h1 = self.layer1(inputs)\n",
    "        out = self.layer2(h1)\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.num_classes\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "model = MyModel(num_classes=10)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对 tf.keras.layers.Layer 进行子类化并实现以下方法来创建自定义层：\n",
    "\n",
    "build：创建层的权重。使用 add_weight 方法添加权重。\n",
    "\n",
    "call：定义前向传播。\n",
    "\n",
    "compute_output_shape：指定在给定输入形状的情况下如何计算层的输出形状。 或者，可以通过实现 get_config 方法和 from_config 类方法序列化层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0810 21:09:33.791243  6468 deprecation.py:506] From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 11.5615 - acc: 0.1020\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 11.5611 - acc: 0.0990\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 11.5596 - acc: 0.0980\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 11.5598 - acc: 0.0990\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 11.5576 - acc: 0.0990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bee51e4da0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "        self.kernel = self.add_weight(name='kernel1', shape=shape,\n",
    "                                   initializer='uniform', trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "model = tf.keras.Sequential([MyLayer(10), layers.Activation('softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 147us/sample - loss: 11.5581 - acc: 0.1010 - val_loss: 11.6532 - val_acc: 0.1150\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 84us/sample - loss: 11.5560 - acc: 0.0990 - val_loss: 11.6512 - val_acc: 0.1150\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 11.5548 - acc: 0.0990 - val_loss: 11.6531 - val_acc: 0.1150\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 11.5536 - acc: 0.0980 - val_loss: 11.6519 - val_acc: 0.1150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1beeb658ba8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "#     tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "    ]\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5,\n",
    "         callbacks=callbacks, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和恢复"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 权重保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 146us/sample - loss: 12.9275 - acc: 0.0930\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 15.0984 - acc: 0.1010\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 17.1111 - acc: 0.0930\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 19.2364 - acc: 0.0970\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 19.7631 - acc: 0.0970\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5)\n",
    "\n",
    "model.save_weights('./ch1/weights/model')\n",
    "model.load_weights('./ch1/weights/model')\n",
    "model.save_weights('./ch1/model.h5')\n",
    "model.load_weights('./ch1/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "序列化为 json:\n",
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': {'build_input_shape': [None, 72],\n",
      "            'layers': [{'class_name': 'Dense',\n",
      "                        'config': {'activation': 'relu',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_19',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 64,\n",
      "                                   'use_bias': True}},\n",
      "                       {'class_name': 'Dense',\n",
      "                        'config': {'activation': 'softmax',\n",
      "                                   'activity_regularizer': None,\n",
      "                                   'bias_constraint': None,\n",
      "                                   'bias_initializer': {'class_name': 'Zeros',\n",
      "                                                        'config': {'dtype': 'float32'}},\n",
      "                                   'bias_regularizer': None,\n",
      "                                   'dtype': 'float32',\n",
      "                                   'kernel_constraint': None,\n",
      "                                   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
      "                                                          'config': {'dtype': 'float32',\n",
      "                                                                     'seed': None}},\n",
      "                                   'kernel_regularizer': None,\n",
      "                                   'name': 'dense_20',\n",
      "                                   'trainable': True,\n",
      "                                   'units': 10,\n",
      "                                   'use_bias': True}}],\n",
      "            'name': 'sequential_4'},\n",
      " 'keras_version': '2.2.4-tf'}\n",
      "----------------------------------------------\n",
      "序列化为 yaml:\n",
      "backend: tensorflow\n",
      "class_name: Sequential\n",
      "config:\n",
      "  build_input_shape: !!python/tuple\n",
      "  - null\n",
      "  - 72\n",
      "  layers:\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: relu\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config:\n",
      "          dtype: float32\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config:\n",
      "          dtype: float32\n",
      "          seed: null\n",
      "      kernel_regularizer: null\n",
      "      name: dense_19\n",
      "      trainable: true\n",
      "      units: 64\n",
      "      use_bias: true\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: softmax\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config:\n",
      "          dtype: float32\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config:\n",
      "          dtype: float32\n",
      "          seed: null\n",
      "      kernel_regularizer: null\n",
      "      name: dense_20\n",
      "      trainable: true\n",
      "      units: 10\n",
      "      use_bias: true\n",
      "  name: sequential_4\n",
      "keras_version: 2.2.4-tf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 序列化成json\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "json_str = model.to_json()\n",
    "# 使用 pprint 美观打印\n",
    "print('序列化为 json:')\n",
    "pprint.pprint(json.loads(json_str))\n",
    "fresh_model = tf.keras.models.model_from_json(json_str)\n",
    "\n",
    "print('----------------------------------------------')\n",
    "\n",
    "# 保持为yaml格式  \n",
    "# 需要提前安装pyyaml\n",
    "yaml_str = model.to_yaml()\n",
    "print('序列化为 yaml:')\n",
    "print(yaml_str)\n",
    "fresh_model = tf.keras.models.model_from_yaml(yaml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存整个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 11.5430 - acc: 0.1040\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 11.5847 - acc: 0.1090\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 11.6595 - acc: 0.0960\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 11.6954 - acc: 0.0960\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 11.7049 - acc: 0.0960\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(10, activation='softmax', input_shape=(72,)),\n",
    "  layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=5)\n",
    "\n",
    "model.save('./ch1/all_model.h5')\n",
    "model = tf.keras.models.load_model('./ch1/all_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将 Keras 用于 Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator API 用于针对分布式环境训练模型。它适用于一些行业使用场景，例如用大型数据集进行分布式训练并导出模型以用于生产"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0810 21:42:23.990992  6468 estimator.py:1811] Using temporary folder as model directory: C:\\Users\\44310\\AppData\\Local\\Temp\\tmp64e3tbtd\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([layers.Dense(10,activation='softmax'),\n",
    "                          layers.Dense(10,activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "estimator = tf.keras.estimator.model_to_estimator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只要用 tf.keras.estimator.model_to_estimator 方法将 tf.keras.Model 转换为 tf.estimator.Estimator 对象, tf.keras.Model 就可以使用 tf.estimator API 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
